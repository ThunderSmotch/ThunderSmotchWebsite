\chapter{Nature of Quantum Systems}

\section{Locality}

Physical systems (at least most of the ones we will be considering in this course) are constituted of a collection of local degrees of freedom coupled to each other. A state of the constituent local system can be written using a basis for the local Hilbert space 
\[ \mathcal{H}_{r}: \ket{\psi(r)} = \sum_{n = 1}^{d_{r}} c_{n} \ket{\phi_{n}(r)}\ , \] 
with dimension 
\( d_{r} \). Note that 
\( d_{r} = 2 \) for a qubit, with 
\( \ket{\phi_{1}} = \ket{\uparrow} \) 
and 
\( \ket{\phi_{2}} = \ket{\downarrow} \). A basis for the total Hilbert space can be obtained by a tensor product of local basis states 
\[ \ket{ \phi_{n_{1}}(r_{1}), \phi_{n_{2}}(r_{2}), \dots} = \ket{\phi_{n_{1}}(r_{1})} \otimes \ket{\phi_{n_{2}}(r_{2})} \otimes \dots \ ,\] 
and thus the total Hilbert space 
\( \mathcal{H} = \otimes_{r} \mathcal{H}_{r} \) has dimension 
\( d_{\mathcal{H}} = \prod_{r} d_{\mathcal{H}_{r}} \) \footnote{Testing footnotes. \( 1 + 1 = 2 \) }. 

\todo{Insert correct footnotes.}

A state of the total system can be written as 
\[\label{eq:totalState} \ket{\Psi} = \sum_{n_{1}n_{2}\dots} c_{n_{1}n_{2}} \ket{\phi_{n_{1}}(r_{1}), \phi_{n_{2}}(r_{2}) }, \dots\ , \]
and, as such, there is a sense on asking how the two degrees of freedom are correlated, or how one of them is correlated with the rest of the system \footnote{Testing again...}.

Due to the nature of physical forces it is also plausible to assume that the interactions between degrees of freedom are pair-wise or limited to few-body terms, i.e., operators can be written as 
\[ O = \sum_{r} A_{r} + \sum_{r r'} A_{r} B_{r'} + \sum_{rr'r''} A_{r} B_{r'} C_{r'} + \dots\ , \] 
where 
\( A_{r},\ B_{r'} \ \text{and}\ C_{r''} \) only act on degrees of freedom at site 
\( r,\ r' \ \text{and}\ r'' \), respectively. These operators are limited to a finite number of terms and if they act non trivially in 
\( k \) sites they are called 
\( k \)-local.

In most physical systems there is also a notion of locality, i.e. of proximity between degrees of freedom. Two local degrees of freedom can only interact if they are sufficiently close. This happens since interacting potentials have finite characteristic length. Fully connected models, or random graphs, can also be considered but often care must be taken in interpreting the results and defining the interactions for sometimes even simple thermodynamic properties are not well defined. Most physical systems have well defined spatial and temporal structure and a notion of distance (i.e. a metric) between sites (or positions) in which the degrees of freedom live.

\todo{IMAGE HERE}

Due to the local nature of degrees of freedom and to the fact that interactions are restricted to a few terms, the Hamiltonian and local observables can be written as 
\( O = \sum_{r} O_{r} \) where 
\( O_{r} \) is bounded to a few (say 
\( k \) ) lattice sites. This fact alone has consequences, for example:
\begin{itemize}
    \item It is meaningful to ask how correlations decay. In fact we can even classify systems according to the nature of that decay.
    \item We can ask how fast can a localized perturbation spread. There are results called Lieb-Robinson bounds regarding the spread of information that can be derived based on these assumptions. The question of how fast the information of a perturbation can spread is definitely something for which quantum information tools can help.
\end{itemize}

\section{The vastness of the Hilbert space}

The above characterization of the Hilbert space of a many-body system has an essential problem: the number of variables we need to encode a state grows exponentially with the number of degrees of freedom. This means that, for example, diagonalizing the Hamiltonian of a few qubits quickly becomes an impossible task (the current record using symmetry techniques is around 30 two-level systems). This is clearly not enough since we want to be able to say something about properties of systems with much much more degrees of freedom, that being electrons in a crystal (say in a mole of atoms 
\( \approx 10^{23} \) ) or qubits in a useful (to be created) quantum memory (say a megabyte 
\( 2^{20} \approx 10^6 \) bytes).

As long as thermodynamic properties are concerned there are a lot of details that we clearly will not care about. Computing specific heat, compressibility, conductivity... should not require the knowledge of the entire wave function. Many-body theory developed within the context of Condensed Matter systems provides a useful set of tools to compute such quantities However, things might be different if you are concerned with other properties, in particular, if we want to follow the time evolution of a system, its full counting statistics or work distribution.

In this context, information theory has given important contributions. For example, it was shown that ground states and Gibbs (i.e thermal) states are substantially simpler than a generic state, in particular, their entanglement follows a so called area law (some of these results will be covered in the future). Also, some of these states can be described in a much more compact way than equation (\ref{eq:totalState}), using a formalism called Matrix Product States, which are a clever way of encoding the wave-function in just a few degrees of freedom.

It has also been intensively investigated the way generic states, evolving under generic local Hamiltonians, thermalize, i.e. observables after a long time only depend on generic conserved quantities like energy and number of particles and are relatively indifferent to the nature of the initial state otherwise (I hope we will be able to cover this topic briefly). Some results (that I hope to discuss later) also indicate that physically meaningful states only explore a corner of the  entire Hilbert space in reasonable (non-exponential) time scales.